{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c0bfe90c-211f-470e-a0ee-c5074565a11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DRNK3GE5  SLEPTIM1  EMTSUPRT  INCOME3  SEXVAR\n",
      "0       NaN       8.0       1.0     99.0       2\n",
      "1       NaN       6.0       1.0      5.0       2\n",
      "2       NaN       5.0       2.0     10.0       2\n",
      "3       NaN       7.0       1.0     77.0       2\n",
      "4      88.0       9.0       1.0      5.0       2\n",
      "5       NaN       7.0       2.0     99.0       1\n",
      "6      88.0       7.0       1.0      8.0       2\n",
      "7       NaN       8.0       1.0      7.0       2\n",
      "8       NaN       6.0       1.0      7.0       2\n",
      "9      88.0       7.0       1.0      7.0       2\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import missingno as msno\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# Optional: Configure matplotlib for inline display in Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "#Loading the Data\n",
    "df = pd.read_csv('brfss_2022_final.csv')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d7bf5f5f-eeb8-4556-9f6e-4e0854a9a52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dummy Features for Categorical Variables\n",
    "\n",
    "df = pd.get_dummies(df, columns=['SEXVAR'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1f5eb279-5bb8-4420-903a-aa06287d7749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DRNK3GE5  SLEPTIM1  EMTSUPRT  INCOME3  SEXVAR_2\n",
      "0       NaN       8.0       1.0     99.0      True\n",
      "1       NaN       6.0       1.0      5.0      True\n",
      "2       NaN       5.0       2.0     10.0      True\n",
      "3       NaN       7.0       1.0     77.0      True\n",
      "4      88.0       9.0       1.0      5.0      True\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "782d5f0b-fac8-4582-a5d3-9d9778e07c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the numeric columns so they are on the same scale using StandardScaler from sklearn\n",
    "\n",
    "# Select numeric columns\n",
    "numeric_columns = ['DRNK3GE5', 'SLEPTIM1', 'EMTSUPRT', 'INCOME3']\n",
    "\n",
    "# Make a Scaler object\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# Fit and transform the numeric data\n",
    "df[numeric_columns] = scaler.fit_transform(df[numeric_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "20c19941-121c-4974-b28d-89baea5b3078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into Testing and Training Datasets\n",
    "\n",
    "# Split data into training and test sets (80% training, 20% test)\n",
    "X = df.drop('DRNK3GE5', axis=1)  # Features (replace TARGET_VARIABLE with your target)\n",
    "y = df['DRNK3GE5']  # Target (replace TARGET_VARIABLE with your target)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e88d1c60-33fe-4375-957f-ee8c20e43219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['DRNK3GE5', 'SLEPTIM1', 'EMTSUPRT', 'INCOME3', 'SEXVAR_2'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "92e15a95-2271-4599-951c-cc4d9df941d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[        nan  0.61140611 -1.6533828  -1.73426812 -1.70730634 -1.57249748\n",
      " -1.68034457  0.31482661 -1.3568033  -1.22199443 -1.59945925 -0.95237671\n",
      " -1.62642102 -1.54553571 -1.49161216 -0.97933848 -1.43768862  0.90798561\n",
      " -1.08718557 -1.38376507 -1.19503266  0.28786484 -1.32984152 -1.41072684\n",
      " -1.30287975 -1.00630025 -1.0602238  -1.51857393 -1.11414734 -1.27591798\n",
      " -1.16807089 -1.46465039 -1.03326202 -0.79060607 -0.87149139 -0.92541493\n",
      " -0.54795012 -0.68275898 -1.14110912 -0.14352353  0.09913243 -1.24895621\n",
      " -0.41314125 -0.52098834 -0.30529416 -0.27833239  0.1260942   0.26090307]\n"
     ]
    }
   ],
   "source": [
    "print(df['DRNK3GE5'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f332017f-8a6a-4165-8455-e0f7c594c669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - MSE: 1325.1794615018318\n",
      "Random Forest Regressor - MSE: 1335.339509576945\n"
     ]
    }
   ],
   "source": [
    "# Using a Random Forest Model for training to predict the target var: DRNK3GE5\n",
    "\n",
    "# Remove rows with missing values\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Prepare the data\n",
    "X = df_cleaned.drop('DRNK3GE5', axis=1)  # Dropping target variable from features\n",
    "y = df_cleaned['DRNK3GE5']  # The target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate the Mean Squared Error for evaluation\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f\"{model_name} - MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8591a8ae-6f7c-4f35-bf6d-9e8cd8dd597f",
   "metadata": {},
   "source": [
    "- Lower MSE indicates a better model performance, so Linear Regression performed slightly better than Random Forest Regressor in this case.\n",
    "- The MSE values are relatively high, which suggests that there might be room for improvement, possibly through additional data preprocessing, feature engineering, or model tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886a89d5-3afd-49a1-865f-c3b4bec62983",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "Looking to see if there are new features that can reveal hidden patterns in this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "38df2504-9318-4f5d-ba3b-c5d5f9d8c2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k9/14wtpz7n6dz958nl7hkt64lw0000gn/T/ipykernel_78274/1308309336.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['DRNK3GE5'].fillna(df['DRNK3GE5'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# # Create a new feature that indicates whether 'DRNK3GE5' is missing\n",
    "df['DRNK3GE5_missing'] = df['DRNK3GE5'].isna().astype(int)\n",
    "\n",
    "# Impute missing values with the median or mean\n",
    "df['DRNK3GE5'].fillna(df['DRNK3GE5'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b899c6b2-7c3e-4db8-900e-b29547ce283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode 'SEXVAR' two categories: 1 and 2 for male and female)\n",
    "df = pd.get_dummies(df, columns=['SEXVAR'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4661507a-1ef3-44f2-8df5-7316b9bb9a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INCOME3 feature contains a wide range of values, which could make models less effective if it is highly skewed. \n",
    "# Trying log-transform it to make it more normally distributed.\n",
    "df['INCOME3_log'] = np.log1p(df['INCOME3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cd73c715-0c10-4b09-b028-af53cc0f2539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SLEPTIM1 feature represents sleep time and might benefit from binning. \n",
    "# Classify sleep hours into categories \"short sleep\", \"normal sleep\", and \"long sleep\"\n",
    "df['sleep_category'] = pd.cut(df['SLEPTIM1'], bins=[0, 5, 7, 10], labels=['short', 'normal', 'long'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d86b167a-2bfd-435c-ae47-c181186098f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hoping for an interaction between SLEPTIM1 and INCOME3\n",
    "# Maybe people with better income sleep more\n",
    "df['sleep_income_interaction'] = df['SLEPTIM1'] * df['INCOME3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a46926c3-eda4-423b-a59e-6c5cc6d307f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EMTSUPRT variable might represent support could create a binary feature that indicates whether someone has adequate support or not.\n",
    "df['has_support'] = df['EMTSUPRT'].apply(lambda x: 1 if x == 1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "74f5f5bf-fac6-4c08-bf71-847edc30dedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing data again on these new features\n",
    "df = df.dropna(subset=['DRNK3GE5'])  # Drop rows with missing target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2fe5413b-afe4-4c46-aa3d-df3b09f25491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the feature set to include in splitting data into predictors and targets\n",
    "X = df[['INCOME3_log', 'SLEPTIM1', 'sleep_category', 'sleep_income_interaction', 'has_support', 'SEXVAR_2']]\n",
    "y = df['DRNK3GE5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "975bd873-dfe8-4493-a25d-1ff4bc1e246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'sleep_category' to a categorical type\n",
    "df['sleep_category'] = pd.Categorical(df['sleep_category'])\n",
    "\n",
    "# Now apply the .cat.codes to encode the categories numerically\n",
    "df['sleep_category'] = df['sleep_category'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d65878de-5ffe-4d11-913c-32b37749e18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalize the feature set for X and y\n",
    "X = df.drop(columns=['DRNK3GE5'])  # Drop target variable from features\n",
    "y = df['DRNK3GE5']  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "062f7344-9c86-4270-b5cd-7324d1e78c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale one more time to prevent bias towards variables with larger values\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data, then transform the test data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8b04fb97-71f7-45d8-96ab-2ca1f9893019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - MSE: 1325.1794615018318\n",
      "Random Forest Regressor - MSE: 1335.5475653299445\n"
     ]
    }
   ],
   "source": [
    "# train models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    # Evaluate performance using Mean Squared Error (MSE)\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f\"{model_name} - MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064cbd6d-8ae1-4a64-b42f-90277da92d44",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "First Set of Results:\n",
    "Linear Regression - MSE: 1325.1794615018318\n",
    "Random Forest Regressor - MSE: 1335.339509576945\n",
    "\n",
    "New Set of Results:\n",
    "Linear Regression - MSE: 1325.1794615018318 (Same)\n",
    "Random Forest Regressor - MSE: 1335.5475653299445\n",
    "\n",
    "Comparison:\n",
    "Linear Regression: The MSE for Linear Regression remains exactly the same between the two sets of results.\n",
    "Random Forest Regressor: The MSE for the Random Forest model has slightly increased (from 1335.34 to 1335.55).\n",
    "\n",
    "Conclusion:\n",
    "The results are very similar between the two sets, with only a small increase in MSE for the Random Forest Regressor in the second round. This suggests that the feature engineering and scaling that was done did NOT significantly improve the model performance in this case.\n",
    "\n",
    "What happened:\n",
    "Feature Engineering Impact: The added features (such as interaction terms and categorical encoding) didn't provide a strong enough signal to improve the performance.\n",
    "\n",
    "Overfitting or Underfitting: The models might be underfitting or overfitting to the data.\n",
    "\n",
    "This data is not providing any signficant findings in the relationship between drinking, emotional support, gender, income, and sleep. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
